{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import biosppy.signals.ecg as ecg\n",
    "import biosppy\n",
    "import neurokit2 as nk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = pd.read_csv('X_train.csv', index_col='id')\n",
    "X_test_raw = pd.read_csv('X_test.csv', index_col='id')\n",
    "y_train_raw = pd.read_csv('y_train.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabfc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab356c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "import scipy.fftpack as sf\n",
    "\n",
    "# array used for frequency content, based on MrBird [1]\n",
    "freq_array = [\n",
    "    0.46981001,\n",
    "    0.94989355,\n",
    "    1.34722766,\n",
    "    1.92037653,\n",
    "    2.45140581,\n",
    "    3.58897684,\n",
    "    5.61198292,\n",
    "    7.85416366,\n",
    "    11.77742192,\n",
    "    19.56926069,\n",
    "]\n",
    "\n",
    "def extract_fft_heartbeat(heartbeat, n = 10, freq_array = freq_array):\n",
    "\n",
    "    fourier_specture = np.abs(fft(heartbeat))\n",
    "    freqs = sf.fftfreq(len(fourier_specture), 1. / 300.)\n",
    "    fourier_specture = fourier_specture[freqs >= 0]\n",
    "    freqs = freqs[freqs >= 0]\n",
    "    \n",
    "    # cut even more base on the freq_array\n",
    "    fourier_specture = fourier_specture[freqs <= freq_array[-1]]\n",
    "    freqs = freqs[freqs <= freq_array[-1]]\n",
    "    \n",
    "    # compute the sums of frequency bands\n",
    "    sums = []\n",
    "    sums.append(np.sum(fourier_specture[freqs <= freq_array[0]]))\n",
    "    for i in range(len(freq_array) - 1):\n",
    "        sum = np.sum(fourier_specture[np.logical_and(freqs > freq_array[i], freqs <= freq_array[i+1])])\n",
    "        sums.append(sum)\n",
    "\n",
    "    # own guesses\n",
    "    #peak_locs = np.argsort(fourier_specture)[0:n]\n",
    "    #peaks = fourier_specture[peak_locs]\n",
    "    #one_percent_quantile = np.quantile(fourier_specture,0.99)\n",
    "    #five_percent_quantile = np.quantile(fourier_specture,0.95)\n",
    "    #ten_percent_quantile = np.quantile(fourier_specture,0.90)\n",
    "    #num_non_zero = np.sum(fourier_specture > 0.1)\n",
    "    \n",
    "    return sums\n",
    "\n",
    "def extract_fft_feature(clean_signal):\n",
    "    _, info = nk.ecg_peaks(ecg_cleaned=clean_signal, sampling_rate=300)\n",
    "    fft_features = []\n",
    "    n_peaks = 10\n",
    "    #fft_features.append(np.array(extract_fft_heartbeat(clean_signal, n_peaks)))\n",
    "    peaks = info['ECG_R_Peaks']\n",
    "    beats = biosppy.signals.ecg.extract_heartbeats(signal=clean_signal, rpeaks=peaks,sampling_rate=300)[\"templates\"]\n",
    "    n_beats = len(beats)\n",
    "    for i in range(n_beats):\n",
    "        fft_features.append(np.array(extract_fft_heartbeat(beats[i], n_peaks)))\n",
    "    \n",
    "    fft_features = list(np.array(fft_features).T)\n",
    "\n",
    "    return fft_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Fourier\n",
    "signal = X_train_raw.iloc[0].dropna().to_numpy(dtype='float32')\n",
    "try:\n",
    "    clean_signal = nk.ecg_clean(signal, sampling_rate=300, method='neurokit')\n",
    "except:\n",
    "    try:\n",
    "        clean_signal = nk.ecg_clean(signal, sampling_rate=300, method='hamilton2002')\n",
    "    except:\n",
    "        try:\n",
    "            clean_signal = nk.ecg_clean(signal, sampling_rate=300, method='elgendi2010')\n",
    "        except:\n",
    "            print(f'Fail')\n",
    "            \n",
    "ff = extract_fft_heartbeat(heartbeat=clean_signal)\n",
    "test = extract_fft_feature(clean_signal = clean_signal)\n",
    "print(len(test))\n",
    "print(len(ff))\n",
    "n = 8000\n",
    "fourier_specture = fft(clean_signal)\n",
    "fft_freq = sf.fftfreq(len(fourier_specture)) * 300\n",
    "fourier_specture = fourier_specture[fft_freq >= 0]\n",
    "fft_freq = fft_freq[fft_freq >= 0]\n",
    "print(np.quantile(fourier_specture,0.9))\n",
    "print(np.sum(fourier_specture > 1))\n",
    "fft_mask = fourier_specture > np.quantile(fourier_specture,0.9)\n",
    "print(f'freq_left = {np.sum(fft_mask)}')\n",
    "fourier_specture = np.multiply(fourier_specture, fft_mask)\n",
    "    \n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "grid = plt.GridSpec(2, 1,hspace=0.6)\n",
    "\n",
    "full_signal = fig.add_subplot(grid[0, 0])\n",
    "fft_comp = fig.add_subplot(grid[1, 0])\n",
    "\n",
    "full_signal.plot(np.arange(len(clean_signal)), clean_signal[0:], color = 'green')\n",
    "#full_signal.plot(fft_sample, x_sin, color = 'blue')\n",
    "full_signal.set_xlim(0,18000)\n",
    "full_signal.set_title('Full Signal')\n",
    "fft_comp.bar(fft_freq, list(fourier_specture), 0.1, color = 'purple')\n",
    "#fft_comp.set_xlim(-10,10)\n",
    "#fft_comp.set_ylim(0, 1)\n",
    "fft_comp.set_title('FFT of full signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "empty = np.empty(1)\n",
    "empty[:] = np.nan\n",
    "\n",
    "def get_pqrst_peaks(data):\n",
    "    p_peaks = []\n",
    "    q_peaks = []\n",
    "    r_peaks_loc = []\n",
    "    s_peaks = []\n",
    "    t_peaks = []\n",
    "    p_amp = []\n",
    "    q_amp = []\n",
    "    r_amp = []\n",
    "    s_amp = []\n",
    "    t_amp = []\n",
    "    templates = ecg.ecg(signal=data, sampling_rate=300, show=False)[\"templates\"]\n",
    "    for template in templates:\n",
    "        # calculate the locations\n",
    "        try:\n",
    "            # get local maximas and minimas with signal library\n",
    "            loc_max = np.array(sp.signal.argrelextrema(template, np.greater))\n",
    "            loc_min = np.array(sp.signal.argrelextrema(template, np.less))\n",
    "            # find the maximum, but cut the search area to the first half to avoid\n",
    "            # finding peaks at the wrong place\n",
    "            r = np.argmax(template[: int(len(template) / 2)])\n",
    "            \n",
    "            # q and s are the first minima after and before the r value\n",
    "            q = loc_min[loc_min < r][-1]\n",
    "            s = loc_min[loc_min > r][0]\n",
    "            # p and t are the first maxima after and before the r value\n",
    "            p = loc_max[loc_max < r][-1]\n",
    "            t = loc_max[loc_max > r][0]\n",
    "            \n",
    "            r_peaks_loc.append(r)\n",
    "            q_peaks.append(q)\n",
    "            s_peaks.append(s)\n",
    "            p_peaks.append(p)\n",
    "            t_peaks.append(t)\n",
    "        except:\n",
    "            ex = 0\n",
    "            r_peaks_loc.append(ex)\n",
    "            q_peaks.append(ex)\n",
    "            s_peaks.append(ex)\n",
    "            p_peaks.append(ex)\n",
    "            t_peaks.append(ex)\n",
    "        try:\n",
    "            r_a = template[r]\n",
    "            p_a = template[p]\n",
    "            q_a = template[q]\n",
    "            s_a = template[s]\n",
    "            t_a = template[t]\n",
    "        \n",
    "            t_amp.append[t_a]\n",
    "            p_amp.append[p_a]\n",
    "            q_amp.append[q_a]\n",
    "            s_amp.append[s_a]\n",
    "            r_amp.append[r_a]\n",
    "        except:\n",
    "            ex = 0\n",
    "            r_amp.append(ex)\n",
    "            q_amp.append(ex)\n",
    "            s_amp.append(ex)\n",
    "            p_amp.append(ex)\n",
    "            t_amp.append(ex)\n",
    "        \n",
    "    peaks = [np.array(p_peaks), np.array(q_peaks),np.array(r_peaks_loc), np.array(s_peaks), np.array(t_peaks)]\n",
    "    amps = [ np.array(p_amp), np.array(q_amp),np.array(r_amp), np.array(s_amp), np.array(t_amp) ]\n",
    "\n",
    "    return peaks, amps\n",
    "\n",
    "# very bad almost never works\n",
    "def get_pqrst_peaks_biosppy(data):\n",
    "    try:\n",
    "        ecg_ret = ecg.ecg(signal=data, sampling_rate=300, show=False)\n",
    "        p_peaks = ecg.getPPositions(ecg_proc=ecg_ret)\n",
    "        q_peaks = ecg.getQPositions(ecg_proc=ecg_ret)\n",
    "        r_peaks = ecg_ret[\"rpeaks\"]\n",
    "        s_peaks = ecg.getSPositions(ecg_proc=ecg_ret)\n",
    "        t_peaks = ecg.getTPositions(ecg_proc=ecg_ret)\n",
    "    except:\n",
    "        return empty, empty, empty, empty, empty\n",
    "\n",
    "    return p_peaks, q_peaks, s_peaks, t_peaks, r_peaks\n",
    "\n",
    "\n",
    "def extract_r_peaks(signal):\n",
    "    _, r_peaks_nk = nk.ecg_peaks(signal, sampling_rate=300)\n",
    "    s = len(r_peaks_nk['ECG_R_Peaks'])\n",
    "    return np.array(r_peaks_nk['ECG_R_Peaks'])\n",
    "\n",
    "def delineate(signal, r_peaks):\n",
    "    try:\n",
    "        _, waves_peak = nk.ecg_delineate(signal, r_peaks, sampling_rate=300, method='dwt')\n",
    "    except:\n",
    "        try:\n",
    "            _, waves_peak = nk.ecg_delineate(signal, r_peaks, sampling_rate=300, method='peak')\n",
    "        except:\n",
    "            _, waves_peak = nk.ecg_delineate(signal, r_peaks, sampling_rate=300, method='cwt')\n",
    "            \n",
    "    return waves_peak\n",
    "\n",
    "def extract_other_peaks(signal, r_peaks):\n",
    "    \n",
    "    if (len(r_peaks) >= 1): \n",
    "        try:\n",
    "            waves_peak = delineate(signal, r_peaks)\n",
    "        except:\n",
    "            return empty, empty, empty, empty, empty\n",
    "\n",
    "        p_peaks = np.array(waves_peak['ECG_P_Peaks'])       \n",
    "        q_peaks = np.array(waves_peak['ECG_Q_Peaks'])\n",
    "        s_peaks = np.array(waves_peak['ECG_S_Peaks'])\n",
    "        t_peaks = np.array(waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "        return p_peaks, q_peaks, s_peaks, t_peaks, r_peaks\n",
    "    else:\n",
    "        return empty, empty, empty, empty, r_peaks\n",
    "\n",
    "def extract_amp(signal, peaks):\n",
    "    amps = []\n",
    "    for p in peaks:\n",
    "        mask = ~np.isnan(p)\n",
    "        p_no_nan = p[mask].astype(int)\n",
    "        amps.append(signal[p_no_nan])\n",
    "    return amps\n",
    "\n",
    "# not working\n",
    "def extract_amp_loc(heartbeats, peaks):\n",
    "    amps = []\n",
    "    for p in peaks:\n",
    "        peak_amps = []\n",
    "        for i, beat in enumerate(heartbeats):\n",
    "            if np.isnan(p[i]):\n",
    "                continue\n",
    "            peak_amps.append(beat[p[i]])\n",
    "        amps.append(np.array(peak_amps))\n",
    "    return amps\n",
    "\n",
    "def extract_relative_pos(signal, left, right):\n",
    "    if right.shape[0] == left.shape[0]:\n",
    "        mask = ~np.logical_or(np.isnan(left), np.isnan(right))\n",
    "        return right[mask] - left[mask]\n",
    "    elif right.shape[0] < left.shape[0]:\n",
    "        return extract_relative_pos(signal, left[1:], right)\n",
    "    else:\n",
    "        return extract_relative_pos(signal, left, right[1:])\n",
    "        \n",
    "def extract_loc(signal, peaks):\n",
    "    q_loc = extract_relative_pos(signal, peaks[0], peaks[1])\n",
    "    r_loc = extract_relative_pos(signal, peaks[0], peaks[2])\n",
    "    s_loc = extract_relative_pos(signal, peaks[0], peaks[3])\n",
    "    t_loc = extract_relative_pos(signal, peaks[0], peaks[4])\n",
    "    return [q_loc, r_loc, s_loc, t_loc]\n",
    "    \n",
    "def extract_loc_hand(peaks):\n",
    "    # assumes that non erroneous values are zero\n",
    "    q_loc = peaks[1] - peaks[0]\n",
    "    r_loc = peaks[2] - peaks[0]\n",
    "    s_loc = peaks[3] - peaks[0]\n",
    "    t_loc = peaks[4] - peaks[0]\n",
    "    return [q_loc, r_loc, s_loc, t_loc]\n",
    "\n",
    "def extract_dur(signal, peaks):\n",
    "    pq_dur  = extract_relative_pos(signal, peaks[0], peaks[1])\n",
    "    qrs_dur = extract_relative_pos(signal, peaks[1], peaks[3])\n",
    "    st_dur  = extract_relative_pos(signal, peaks[3], peaks[4])\n",
    "    return [pq_dur, qrs_dur, st_dur]\n",
    "\n",
    "def extract_dur_and(peaks):\n",
    "    pq_dur  = peaks[1] - peaks[0]\n",
    "    qrs_dur = peaks[3] - peaks[1] \n",
    "    st_dur  = peaks[4] - peaks[3]\n",
    "    return [pq_dur, qrs_dur, st_dur]\n",
    "\n",
    "def extract_abs_diff_dur(durs):\n",
    "    diffs_durs = []\n",
    "    for dur in durs:\n",
    "        np_dur = np.array(dur)\n",
    "        n = len(np_dur)\n",
    "        diffs_durs.append(np.abs(np_dur[1:n] - np_dur[0:n-1]))\n",
    "    return diffs_durs\n",
    "\n",
    "def extract_int(signal, peaks):\n",
    "    if(len(peaks) > 1):\n",
    "        rr_int = extract_relative_pos(signal, peaks[2][:-1], peaks[2][1:])\n",
    "        pp_int = extract_relative_pos(signal, peaks[0][:-1], peaks[0][1:])\n",
    "        tt_int = extract_relative_pos(signal, peaks[4][:-1], peaks[4][1:])\n",
    "        return [pp_int, rr_int, tt_int]\n",
    "    else:\n",
    "        rr_int = extract_relative_pos(signal, peaks[0][:-1], peaks[0][1:])\n",
    "        return [rr_int]\n",
    "\n",
    "def extract_qrs_complex(signal, peaks):\n",
    "    \n",
    "    if (peaks[1].shape[0] != peaks[2].shape[0] or peaks[2].shape[0] != peaks[3].shape[0]):\n",
    "        return [empty, empty, empty, empty]\n",
    "    \n",
    "    mask = ~np.logical_or.reduce(np.array([np.isnan(peaks[1]), np.isnan(peaks[2]), np.isnan(peaks[3])]))\n",
    "    q = peaks[1][mask].astype(int)\n",
    "    r = peaks[2][mask].astype(int)\n",
    "    s = peaks[3][mask].astype(int)\n",
    "    q_amp = signal[q]\n",
    "    r_amp = signal[r]\n",
    "    s_amp = signal[s]\n",
    "    qr_amp = q_amp + r_amp\n",
    "    qrs_wave = np.divide(q_amp, qr_amp)\n",
    "    qr_wave = np.divide(q_amp, r_amp)\n",
    "    rs_wave = np.divide(s_amp, r_amp)\n",
    "    return [qr_amp, qrs_wave, qr_wave, rs_wave]\n",
    "\n",
    "def extract_qrs_hand(amps):\n",
    "\n",
    "    # peaks always have the same lengh\n",
    "    #if (peaks[1].shape[0] != peaks[2].shape[0] or peaks[2].shape[0] != peaks[3].shape[0]):\n",
    "    #    return [empty, empty, empty, empty]\n",
    "    \n",
    "    q_amp = amps[1]\n",
    "    r_amp = amps[2]\n",
    "    s_amp = amps[3]\n",
    "    qr_amp = q_amp + r_amp\n",
    "    qrs_wave = np.divide(q_amp, qr_amp, out=np.zeros_like(qr_amp).astype(float), where=(qr_amp!=0))\n",
    "    qr_wave = np.divide(q_amp, r_amp, out=np.zeros_like(r_amp).astype(float), where=(r_amp!=0))\n",
    "    rs_wave = np.divide(r_amp, s_amp, out=np.zeros_like(s_amp).astype(float), where=(s_amp!=0))\n",
    "    return [qr_amp, qrs_wave, qr_wave, rs_wave]\n",
    "    \n",
    "\n",
    "def get_phases(signal, r_peaks):\n",
    "    pass\n",
    "\n",
    "def extract_ecg_data(signal, peak_meth = \"hand\"):\n",
    "    \n",
    "    #Check if signal is inverted and correct it if necessary\n",
    "    \n",
    "    signal, is_inverted = nk.ecg_invert(signal, sampling_rate=300, show=False)\n",
    "    \n",
    "    # Variable with additional values\n",
    "    ind = []\n",
    "    \n",
    "    # Extract r peak\n",
    "    r_peaks = extract_r_peaks(signal)\n",
    "    \n",
    "    # Extract other peaks\n",
    "    if peak_meth == \"bio\":\n",
    "        p_peaks, q_peaks, s_peaks, t_peaks, r_peaks = get_pqrst_peaks_biosppy(signal)\n",
    "        peaks = [p_peaks, q_peaks, r_peaks, s_peaks, t_peaks]\n",
    "        # Extract amplitudes\n",
    "        amps = extract_amp(signal, peaks)\n",
    "    elif peak_meth == \"nk\":\n",
    "        p_peaks, q_peaks, s_peaks, t_peaks, _ = extract_other_peaks(signal, r_peaks=r_peaks)\n",
    "        peaks = [p_peaks, q_peaks, r_peaks, s_peaks, t_peaks]\n",
    "        # Extract amplitudes\n",
    "        amps = extract_amp(signal, peaks)\n",
    "        # Extract qrs complex\n",
    "        qrs_complex = extract_qrs_complex(signal, peaks)\n",
    "        # Extract locations\n",
    "        locs = extract_loc(signal, peaks)\n",
    "        # Extract durations\n",
    "        durs = extract_dur(signal, peaks)\n",
    "        # Extract intervals\n",
    "        ints = extract_int(signal, peaks)\n",
    "    else:\n",
    "        peaks, amps = get_pqrst_peaks(signal)\n",
    "        # Extract qrs complex\n",
    "        qrs_complex = extract_qrs_hand(amps)\n",
    "        # Extract locations\n",
    "        locs = extract_loc_hand(peaks)\n",
    "        # Extract durations\n",
    "        durs = extract_dur_and(peaks)\n",
    "        # Extract intervals\n",
    "        ints = extract_int(signal, [r_peaks])\n",
    "    \n",
    "    \n",
    "    # Diffs in the peaksof\n",
    "    diff_amps = extract_abs_diff_dur(amps)\n",
    "    \n",
    "    # Extract difference of durations\n",
    "    diff_dur = extract_abs_diff_dur(durs)\n",
    "\n",
    "    # Extract interval differences\n",
    "    diff_ints = extract_abs_diff_dur(ints)\n",
    "    \n",
    "    # Extract quality of signal\n",
    "    #signal_quality = get_signal_quality(signal, r_peaks)\n",
    "    \n",
    "    # ECG-Rate \n",
    "    ecg_rate = [np.array(nk.signal_rate(r_peaks, sampling_rate=300, desired_length=None))]\n",
    "    \n",
    "    # Get phases\n",
    "    #ecg_phases = get_phases(signal, r_peaks)\n",
    "    \n",
    "    data = amps + locs + durs + ints + qrs_complex + ecg_rate + diff_ints + diff_dur + diff_amps\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a96ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hrvanalysis\n",
    "def extract_hrv_features(r_peaks):\n",
    "    tdf_names = [\n",
    "        \"mean_nni\",\n",
    "        \"sdnn\",\n",
    "        \"sdsd\",\n",
    "        \"nni_50\",\n",
    "        \"pnni_50\",\n",
    "        \"nni_20\",\n",
    "        \"pnni_20\",\n",
    "        \"rmssd\",\n",
    "        \"median_nni\",\n",
    "        \"range_nni\",\n",
    "        \"cvsd\",\n",
    "        \"cvnni\",\n",
    "        \"mean_hr\",\n",
    "        \"max_hr\",\n",
    "        \"min_hr\",\n",
    "        \"std_hr\",\n",
    "    ]\n",
    "\n",
    "    gf_names = [\"triangular_index\"]\n",
    "\n",
    "    fdf_names = [\"lf\", \"hf\", \"lf_hf_ratio\", \"lfnu\", \"hfnu\", \"total_power\", \"vlf\"]\n",
    "\n",
    "    cscv_names = [\n",
    "        \"csi\",\n",
    "        \"cvi\",\n",
    "        \"Modified_csi\",\n",
    "    ]\n",
    "\n",
    "    pcp_names = [\"sd1\", \"sd2\", \"ratio_sd2_sd1\"]\n",
    "    features = np.ndarray((len(tdf_names) + len(gf_names) + len(fdf_names) + len(cscv_names) + len(pcp_names),))\n",
    "    features[:] = 0\n",
    "    features = list(features)\n",
    "    \n",
    "    try:\n",
    "        tdf = hrvanalysis.get_time_domain_features(r_peaks)\n",
    "        gf = hrvanalysis.get_geometrical_features(r_peaks)\n",
    "        fdf = hrvanalysis.get_frequency_domain_features(r_peaks)\n",
    "        cscv = hrvanalysis.get_csi_cvi_features(r_peaks)\n",
    "        pcp = hrvanalysis.get_poincare_plot_features(r_peaks)\n",
    "        samp = hrvanalysis.get_sampen(r_peaks)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    for name in tdf_names:\n",
    "        features.append(tdf[name])\n",
    "\n",
    "    for name in gf_names:\n",
    "        features.append(gf[name])\n",
    "\n",
    "    for name in fdf_names:\n",
    "        features.append(fdf[name])\n",
    "\n",
    "    for name in cscv_names:\n",
    "        features.append(cscv[name])\n",
    "\n",
    "    for name in pcp_names:\n",
    "        features.append(pcp[name])\n",
    "\n",
    "    features.append(samp[\"sampen\"])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heartpy as hp\n",
    "def extract_hp_features(signal):\n",
    "    try:\n",
    "        _, measures = hp.process(signal, sample_rate=300)\n",
    "    except:\n",
    "        try:\n",
    "            _, measures = hp.process(hp.flip_signal(signal), sample_rate=300)\n",
    "        except:\n",
    "            print(\"hp fail\")\n",
    "            return [np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, np.NaN]\n",
    "\n",
    "    features = []\n",
    "    features.append(measures[\"pnn50\"])\n",
    "    features.append(measures[\"pnn20\"])\n",
    "    features.append(measures[\"sd1\"])\n",
    "    features.append(measures[\"sd2\"])\n",
    "    features.append(measures[\"s\"])\n",
    "    features.append(np.log10(measures[\"sd1/sd2\"] ** 2))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_template_features(signal):\n",
    "    templates = ecg.ecg(signal=signal, sampling_rate=300, show=False)[\"templates\"]\n",
    "\n",
    "    med_template = np.median(templates, axis=0)\n",
    "    med_std = np.std(med_template)\n",
    "    med_mean = np.mean(med_template)\n",
    "    med_med = np.median(med_template)\n",
    "\n",
    "    mean_template = np.mean(templates, axis=0)\n",
    "    mean_std = np.std(mean_template)\n",
    "    mean_mean = np.mean(mean_template)\n",
    "    mean_med = np.median(mean_template)\n",
    "\n",
    "    std_template = np.std(templates, axis = 0)\n",
    "    std_std = np.std(std_template)\n",
    "    std_mean = np.mean(std_template)\n",
    "    std_med = np.median(std_template)\n",
    "\n",
    "    return [med_std, med_mean, med_med, mean_std, mean_mean, mean_med, std_std, std_mean, std_med]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3961c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_to_noise_dB(signal):\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    return [20 * np.log10(abs(np.where(std == 0, 0, mean / std)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5fc88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_over_thresh(signal, r_peaks, thresh):\n",
    "    thres = np.max(signal) * thresh\n",
    "    thresh_rate = sum(signal > thres) / len(signal)\n",
    "    thresh_over_peak = thresh_rate / len(r_peaks)\n",
    "    return [thresh_rate, thresh_over_peak]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(ecg_data):\n",
    "    features = []\n",
    "    for x in ecg_data:\n",
    "        if len(x) > 0:\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            median = np.median(x)\n",
    "            min = np.min(x)\n",
    "            max = np.max(x)\n",
    "            skew = sp.stats.skew(x)\n",
    "            kurtosis = sp.stats.kurtosis(x)\n",
    "            variation = sp.stats.variation(x)\n",
    "            iqr = sp.stats.iqr(x) # difference between the 0.75 and 0.25 quantile\n",
    "            slope = x[0] - x[-1] #not really, but w/e\n",
    "            new_features = [mean, std, median, min, max, skew, kurtosis, variation, iqr, slope] \n",
    "            features += new_features\n",
    "        else:\n",
    "            with open('filename.txt', 'a') as f:\n",
    "                original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "                sys.stdout = f # Change the standard output to the file we created.\n",
    "                print(f'No data for ecgdata ')\n",
    "                sys.stdout = original_stdout\n",
    "\n",
    "            features += [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature = create_features(ecg_data)\n",
    "signal = X_train_raw.iloc[0].dropna().to_numpy(dtype='float32')\n",
    "meth = \"hand\"\n",
    "cleaned_signal = nk.ecg_clean(signal, sampling_rate=300, method='neurokit')\n",
    "ecg_data = extract_ecg_data(cleaned_signal, meth)\n",
    "fft_data = extract_fft_feature(clean_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_features(df_raw_signals):\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for i in tqdm(range(0, df_raw_signals.shape[0])):\n",
    "        signal = df_raw_signals.iloc[i].dropna().to_numpy(dtype='float32')\n",
    "        meth = \"nk\"\n",
    "        try:\n",
    "            cleaned_signal = nk.ecg_clean(signal, sampling_rate=300, method='neurokit')\n",
    "            ecg_data = extract_ecg_data(cleaned_signal, meth)\n",
    "        except:\n",
    "            try:\n",
    "                cleaned_signal = nk.ecg_clean(signal, sampling_rate=300, method='hamilton2002')\n",
    "                ecg_data = extract_ecg_data(cleaned_signal, meth)\n",
    "            except:\n",
    "                try:\n",
    "                    cleaned_signal = nk.ecg_clean(signal, sampling_rate=300, method='elgendi2010')\n",
    "                    ecg_data = extract_ecg_data(cleaned_signal, meth)\n",
    "                except:\n",
    "                    print('really bad data point', i)\n",
    "                    #exit(-1)\n",
    "        fft_data = extract_fft_feature(cleaned_signal)\n",
    "        r_peaks = extract_r_peaks(cleaned_signal)\n",
    "        hrv_features = extract_hrv_features(r_peaks)\n",
    "        hp_fetures = extract_hp_features(cleaned_signal)\n",
    "        s_over_features = s_over_thresh(cleaned_signal, r_peaks, 0.7)\n",
    "        template_features = extract_template_features(cleaned_signal)\n",
    "        s_to_noise_feature = s_to_noise_dB(cleaned_signal)\n",
    "        \n",
    "\n",
    "        f = list(create_features(ecg_data)) + list(create_features(fft_data)) + hrv_features + hp_fetures + s_over_features + template_features + s_to_noise_feature\n",
    "        features.append(f)\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(features)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d230d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def sub_features(arg_tuple):\n",
    "    df_raw, idx = arg_tuple\n",
    "    df_processed = get_features(df_raw)\n",
    "    return idx, df_processed\n",
    "\n",
    "def multi_features(df_raw_signals, n_cores=128):\n",
    "    ids = df_raw_signals.index.to_list()\n",
    "    split = np.array_split(ids, n_cores)\n",
    "    \n",
    "    chunks = []\n",
    "    for l, i in zip(split, range(len(split))):\n",
    "        start = l[0]\n",
    "        end = l[-1]\n",
    "        chunks.append((df_raw_signals.iloc[start:end+1], i))\n",
    "    \n",
    "    my_pool = Pool(n_cores)\n",
    "    result = my_pool.map(sub_features, chunks)\n",
    "    result = sorted(result, key=lambda tup: tup[0])\n",
    "    \n",
    "    df_list = [item[1] for item in result]\n",
    "    df_final = pd.concat(df_list)\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    \n",
    "    return df_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train features\n",
    "features = multi_features(X_train_raw)\n",
    "features.to_csv('train_features.csv')\n",
    "features = pd.read_csv('train_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4370d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test features\n",
    "test_features = multi_features(X_test_raw)\n",
    "test_features.to_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188704f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fefa6b19965aa5f0c22c15aa51ef8a95a0e8040e71d92558b5c36621141f9dff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
