{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee52b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Data\n",
    "df_train = pd.read_csv('X_train.csv')\n",
    "df_labels = pd.read_csv('y_train.csv')\n",
    "df_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "df_id = df_test.iloc[:,0:1]\n",
    "\n",
    "# Remove first column\n",
    "df_X = df_train.iloc[:,1:]\n",
    "df_y = df_labels.iloc[:,1:]\n",
    "df_test = df_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff575cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "df_all = pd.concat([df_X, df_y], axis=1)\n",
    "shuffled_all = df_all.sample(frac=1, random_state=0)\n",
    "\n",
    "df_X = shuffled_all.iloc[:,:-1]\n",
    "df_y = shuffled_all.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693cf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "\n",
    "def remove_X_correlated_features(X_train, alpha=0.99):\n",
    "    \n",
    "    dcor_tr = DropCorrelatedFeatures(threshold=alpha)\n",
    "    X_train_decr = dcor_tr.fit(X_train)\n",
    "\n",
    "    mask = dcor_tr.get_support()\n",
    "    return np.array(mask)\n",
    "\n",
    "def fs_x_correlation(X_train, X_test, alpha=0.99):\n",
    "    \n",
    "    mask1 = remove_X_correlated_features(X_train, alpha=alpha)\n",
    "    \n",
    "    X_train_decor = X_train[:, mask1]\n",
    "    X_test_decor = X_test[:, mask1]\n",
    "    \n",
    "    return X_train_decor, X_test_decor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "def drop_constant_features(X_train, X_test):\n",
    "    \n",
    "    dconst_tr = DropConstantFeatures(missing_values='ignore')\n",
    "    X_train_dedup = dconst_tr.fit_transform(X_train)\n",
    "    X_test_dedup = dconst_tr.transform(X_test)\n",
    "    \n",
    "    return X_train_dedup, X_test_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d97ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_nan_feature_selection(X_train, y_train, X_test, alpha_X=0.99, alpha_y=0.1):\n",
    "\n",
    "    X_train, X_test = fs_x_correlation(X_train, X_test, alpha=alpha_X)\n",
    "    X_train, X_test = drop_constant_features(X_train, X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "def impute_knn(X_train, X_test, n=20):\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=n)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed\n",
    "\n",
    "def impute_median(X_train, X_test):\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(X_train, X_val):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b804a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def select_k_best(X_train, y_train, X_test, k, score_func):\n",
    "    \n",
    "    kbest = SelectKBest(k=k, score_func=score_func)\n",
    "    X_train_selected = kbest.fit_transform(X_train, y_train)\n",
    "    X_test_selected = kbest.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "def scale_and_impute(X_train, X_test):\n",
    "    \n",
    "    scale_and_impute_pipe = Pipeline([('scaler', StandardScaler()),('imputer', SimpleImputer(strategy='median'))])\n",
    "    X_train_imputed = scale_and_impute_pipe.fit_transform(X_train)\n",
    "    X_test_imputed = scale_and_impute_pipe.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "\n",
    "def outlier_detection(X_train, y_train, contamination=0.01):\n",
    "\n",
    "    mask3 = ECOD_outlier_detection(X_train, y_train, contamination)\n",
    "    \n",
    "    mask = mask3.astype(int) == 1\n",
    "    \n",
    "    X_return = X_train[mask]\n",
    "    y_return = y_train[mask]\n",
    "    \n",
    "    print(X_train.shape, X_return.shape)\n",
    "    \n",
    "    return X_return, y_return\n",
    "    \n",
    "def ECOD_outlier_detection(X_train, y_train, contamination=0.01):\n",
    "    \n",
    "    estimator = ECOD(contamination=contamination)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    distance = estimator.predict(X_train)\n",
    "    mask = distance != 1\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae40616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection before nan value imputation\n",
    "X_train_raw = df_X.to_numpy()\n",
    "y_train_raw = df_y.to_numpy().ravel()\n",
    "X_test_raw = df_test.to_numpy()\n",
    "\n",
    "X_train_selected_nan, X_test_selected_nan = with_nan_feature_selection(X_train_raw, y_train_raw, X_test_raw, alpha_X=0.9999)\n",
    "print(X_train_selected_nan.shape, X_train_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan value imputation\n",
    "X_train_selected, X_test_selected = impute_median(X_train_selected_nan, X_test_selected_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97630162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection after nan value imputation\n",
    "from scipy.stats import spearmanr, f, pearsonr\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, chi2, f_classif\n",
    "\n",
    "def f_spearman(X, y):\n",
    "    corr_array = []\n",
    "    p_array = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr, p = spearmanr(X[:,i], y)\n",
    "        corr_array.append(abs(corr))\n",
    "        p_array.append(p)\n",
    "        \n",
    "    return corr_array, p_array\n",
    "\n",
    "\n",
    "X_train_kselected, X_test_kselected = select_k_best(X_train_selected, y_train_raw, X_test_selected, \n",
    "                                                    k=175, score_func=f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "X_train_no_outliers, y_train_no_outliers = outlier_detection(X_train_kselected, y_train_raw, contamination=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0faf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "X_train_scaled, X_test_scaled = scale(X_train_no_outliers, X_test_kselected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe276231",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "y_train = y_train_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def get_best_parameters(estimator, parameters):\n",
    "    \n",
    "    search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='r2', n_jobs=-1, cv=5, verbose=1)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print('Best params:', search.best_params_)\n",
    "    print('score:', search.best_score_)\n",
    "    print('best:', search.best_estimator_)\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rational_kernel = RationalQuadratic(alpha=0.6, length_scale=8)\n",
    "gpr = GaussianProcessRegressor(random_state=0)\n",
    "gpr_parameters = {'kernel' : [rational_kernel], 'alpha' : np.logspace(-10, -1, 20), 'normalize_y' : [True, False]}\n",
    "gpr_final = get_best_parameters(gpr, gpr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0276406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cubist import Cubist\n",
    "\n",
    "cub = Cubist(n_rules=500, composite=True, random_state=0)\n",
    "cub_parameters = {'n_committees' : [1, 2, 3, 4, 5, 6, 7, 8, 9], 'neighbors' : [3, 4, 5, 6]}\n",
    "cub_final = get_best_parameters(cub, cub_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rational_kernel = RationalQuadratic(alpha=0.6, length_scale=8)\n",
    "svr = SVR()\n",
    "svr_parameters = {'kernel' : ['rbf', rational_kernel], 'epsilon' : np.logspace(-8, -1, 8), 'C' : np.linspace(50, 80, 10)}\n",
    "svr_final = get_best_parameters(svr, svr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852189a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb = LGBMRegressor(random_state=0)\n",
    "lgb_parameters = {'boosting_type' : ['gbdt'], 'n_estimators' : [2000], 'learning_rate' : np.logspace(-3, 0, 6), 'num_leaves' : np.logspace(3, 5, 3, base=2).astype(int)}\n",
    "lgb_final = get_best_parameters(lgb, lgb_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "gbr_parameters = {'n_estimators' : [2000], 'learning_rate' : np.logspace(-5, 0, 10), 'min_samples_split' : [2, 3, 4, 5, 6], 'max_depth' : [2, 3, 4]}\n",
    "gbr_final = get_best_parameters(gbr, gbr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe52bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "trees = ExtraTreesRegressor(random_state=0)\n",
    "trees_parameters = {'n_estimators' : [2000], 'min_samples_split' : [2, 3, 4, 5, 6]}\n",
    "trees_final = get_best_parameters(trees, trees_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "cat = CatBoostRegressor(verbose=False)\n",
    "cat_parameters = {'learning_rate' : np.logspace(-5, 0, 10)}\n",
    "cat_final = get_best_parameters(cat, cat_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ab910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn_rvm import EMRVR\n",
    "from skrvm import RVR\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rational_kernel = RationalQuadratic(alpha=0.6, length_scale=8)\n",
    "rvr = RVR()\n",
    "rvr_parameters = {'kernel' : ['rbf', rational_kernel]}\n",
    "rvr_final = get_best_parameters(rvr, rvr_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svr', svr_final), ('lgb', lgb_final), ('trees', trees_final), ('cat', cat_final), ('rvr', rvr_final), ('cub', cub_final), ('gpr', gpr_final)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "K = 5\n",
    "cv_splitter = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ef5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, regressor in estimators:\n",
    "    \n",
    "    score = cross_val_score(estimator=regressor, X=X_train, y=y_train, cv=cv_splitter, scoring='r2', n_jobs=-1)\n",
    "    mean_score = np.mean(score)\n",
    "\n",
    "    print(f\"{name}: {K} fold CV score is {mean_score} and the list is \\n{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=estimators, n_jobs=-1)\n",
    "score = cross_val_score(estimator=stacking_regressor, X=X_train, y=y_train, cv=cv_splitter, scoring='r2', verbose=3)\n",
    "mean_score = np.mean(score)\n",
    "\n",
    "print(f\"Stacking: {K} fold CV score is {mean_score} and the list is \\n{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf649cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to all training data\n",
    "stacking_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Submission\n",
    "y_predict = stacking_regressor.predict(X_test)\n",
    "df_submission = df_id.assign(y=y_predict)\n",
    "print(df_submission)\n",
    "df_submission.to_csv('current.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd75152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
